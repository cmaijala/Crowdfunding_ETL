# Crowdfunding_ETL
![cowomen-cKQkMFzXHAI-unsplash](https://github.com/user-attachments/assets/504c9cce-19c3-4d11-bfd4-cf923960bccd)

Photo by <a href="https://unsplash.com/@cowomen?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">CoWomen</a> on <a href="https://unsplash.com/photos/a-group-of-women-sitting-around-a-wooden-table-cKQkMFzXHAI?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>

## Project 2 for the University Of Minnesota Data Visualization and Analytics Boot Camp

### Contributors: Chinna Maijala, Abigail Serpa, and Kat Chu
  
# Project Overview

## For the ETL mini project, we focused practicing building an ETL pipeline using Python, Pandas, and either Python dictionary methods or regular expressions to extract and transform the data. After transforming the data, we created four CSV files and use the CSV file data to create an ERD and a table schema. Finally, we uploaded the CSV file data into a Postgres database.

# Objective
## The instructions for this mini project are divided into the following subsections:

  * ### Create the Category and Subcategory DataFrames
    <img width="1000" alt="image" src="https://github.com/user-attachments/assets/dbd83c39-80ce-4758-bd09-aac8790aaf9a">
  * ### Create the Campaign DataFrame
    <img width="1600" alt="image" src="https://github.com/user-attachments/assets/a6c7f4e6-8268-4848-a78a-ee3bf62466c3">
  * ### Create the Contacts DataFrame
    <img width="500" alt="image" src="https://github.com/user-attachments/assets/e7c9bb20-505b-4319-8f9e-19fbe48fd419">
  * ### Create the Crowdfunding Database
    <img width="1400" alt="image" src="https://github.com/user-attachments/assets/2226079c-6591-4c9b-b985-4729c9815df0">

# ETL Process
## Extract
  * ### Data Sources: Describe where the data was sourced from (e.g., databases, APIs, files).
  * ### Methods: Explain how the data was extracted (e.g., SQL queries, web scraping).

## Transform
  * ### Data Cleaning: Outline the steps taken to clean the data (e.g., handling missing values, normalization).
  * ### Data Transformation: Detail any transformations applied (e.g., aggregating data, changing data types).
## Load
  * ### Target Database: Specify where the transformed data was loaded (e.g., data warehouse, cloud storage).
  * ### Loading Process: Describe the methods used for loading the data (e.g., bulk loading, real-time loading).
# Entity-Relationship Diagram:
----insert ERD image here-------


# Conclusions:
  * ### Key Findings: Summarize the main insights gained from the project.
  * ### Impact: Discuss the implications of your findings and any potential applications.


## References
### Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.









